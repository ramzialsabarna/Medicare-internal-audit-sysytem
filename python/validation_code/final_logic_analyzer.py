import re
import csv
import os
import time
from pathlib import Path

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ---
BASE_DIR = Path(r"C:\Users\pc\Desktop\phd file draft\phd new\Ø¬Ø§Ù…Ø¹Ù‡ Ø§Ø´Ø¨ÙŠÙ„ÙŠÙ‡\Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø§ÙŠØ²Ùˆ\vs code\medicareinternalaudit")
# Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³Ù„ÙŠÙ… (ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 50 Ù…Ù„Ù ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ c1-c5)
KR_CLEAN_DIR = BASE_DIR / "kr_outputs_10models"
# Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¹ÙŠÙˆØ¨ (Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 50 Ù…Ù„Ù DEFECTIVE_*)
KR_DEFECTIVE_DIR = BASE_DIR / "structurecode" / "kr_outputs_defective"
# Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
OUTPUT_CSV = BASE_DIR / "structurecode" / "phd_comprehensive_results.csv"

def analyze_logic_defects(kr_content):
    """Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ÙŠ Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ù…ÙŠØªØ© (DF1)."""
    dead_features = []
    
    # 1. Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ©
    mandatories = ["InternalAuditSystem"] 
    m_matches = re.findall(r"group\(.*?,mandatory,\[(.*?)\]\)\.", kr_content)
    for match in m_matches:
        mandatories.extend([f.strip() for f in match.split(',')])

    # 2. Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©
    optionals = []
    o_matches = re.findall(r"group\(.*?,optional,\[(.*?)\]\)\.", kr_content)
    for match in o_matches:
        optionals.extend([f.strip() for f in match.split(',')])

    # 3. Ø§ÙƒØªØ´Ø§Ù Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ (imp)
    exclusions = re.findall(r"imp\(\s*([^,]+?)\s*,\s*not\(\s*([^)]+?)\s*\)\s*\)\.", kr_content)
    
    for feat_a, feat_b in exclusions:
        if feat_a in mandatories and feat_b in optionals:
            dead_features.append(feat_b)
        elif feat_b in mandatories and feat_a in optionals:
            dead_features.append(feat_a)
            
    return list(set(dead_features))

def run_comprehensive_analysis():
    all_results = []
    targets = [
        {"path": KR_CLEAN_DIR, "type": "Clean (Original)"},
        {"path": KR_DEFECTIVE_DIR, "type": "Defective (Injected)"}
    ]

    print(f"\n{'Group':<20} | {'Model Name':<45} | {'NF':<5} | {'NDF':<5} | {'Time (s)'}")
    print("-" * 105)

    total_files = 0
    start_all = time.perf_counter()

    for target in targets:
        dir_path = target["path"]
        if not dir_path.exists():
            print(f"âš ï¸ Warning: Folder not found: {dir_path}")
            continue

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª .kr.pl (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… rglob Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø£ÙŠØ¶Ø§Ù‹)
        for kr_file in sorted(dir_path.rglob("*.kr.pl")):
            try:
                # --- Ø¨Ø¯Ø¡ Ù‚ÙŠØ§Ø³ Ø§Ù„ÙˆÙ‚Øª Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ÙˆØ§Ø­Ø¯ ---
                start_model = time.perf_counter()
                
                content = kr_file.read_text(encoding="utf-8")
                # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª (NF)
                nf_count = len(re.findall(r"feature\(.*?\)\.", content))
                # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹ÙŠÙˆØ¨
                dead_list = analyze_logic_defects(content)
                
                # --- Ù†Ù‡Ø§ÙŠØ© Ù‚ÙŠØ§Ø³ Ø§Ù„ÙˆÙ‚Øª Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ÙˆØ§Ø­Ø¯ ---
                model_duration = time.perf_counter() - start_model
                
                all_results.append({
                    "Folder": target["type"],
                    "Model": kr_file.name,
                    "NF": nf_count,
                    "NDF": len(dead_list),
                    "Execution_Time": model_duration, # Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯
                    "Detected": ", ".join(dead_list) if dead_list else "None"
                })
                
                print(f"{target['type']:<20} | {kr_file.name:<45} | {nf_count:<5} | {len(dead_list):<5} | {model_duration:.4f}")
                total_files += 1
            except Exception as e:
                print(f"âŒ Error processing {kr_file.name}: {e}")

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    if all_results:
        try:
            with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:
                # Ø£Ø¶ÙÙ†Ø§ Execution_Time Ø¥Ù„Ù‰ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
                fieldnames = ["Folder", "Model", "NF", "NDF", "Execution_Time", "Detected"]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(all_results)
            
            total_duration = time.perf_counter() - start_all
            print("-" * 105)
            print(f"âœ… SUCCESS! Processed {total_files} models in {total_duration:.2f} seconds.")
            print(f"ğŸ“„ Master spreadsheet with Time data saved at: {OUTPUT_CSV}")
        except PermissionError:
            print(f"\nâŒ CRITICAL: Please close '{OUTPUT_CSV.name}' in Excel and run again!")
    else:
        print("\nâŒ No models were found. Check your directories.")

if __name__ == "__main__":
    run_comprehensive_analysis()